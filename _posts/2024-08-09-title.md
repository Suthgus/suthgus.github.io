---
layout: post
title:  "로지스틱 회귀"
date : 2024-08-09 00:25:20 +0700
---
# 4-1 로지스틱 회귀     
생선 럭키백을 만든다고 가정해보자.      
럭키백에 무엇이 들어있는지는 알 수 없고, 포함된 생선의 확률만 알 수 있다.      
생선의 확률을 어떻게 구할 수 있을까?     

### 럭키백의 확률
k-최근접 이웃 분류기를 이용해서 이웃 클래스 비율을 확률이라고 출력할 수 있다.     
![image](https://github.com/user-attachments/assets/7e64b8df-df30-443c-bb94-530bd6ddc9d1)     
![image](https://github.com/user-attachments/assets/3d6e6d49-e902-4d5d-8450-9f73dca0d5ee)     
- read_csv()함수로 csv 파일을 데이터 프레인으로 변환 (csv파일의 첫줄을 자동으로 열제목으로 만들어줌)     
- 판다스의 unique 함수를 통해 어떤 종류의 생선이 있는지 species열에서 고유한 값 추출     
- species 열을 타깃으로 만들고 나머지 5개 열은 입력데이터로 사용 - 대괄호 두 개 [[ ]]는 여러 열을 선택할 때 사용     
![image](https://github.com/user-attachments/assets/d4f63097-2748-416c-8503-20e49d6dfa48)     
- 데이터를 훈련세트와 테스트세트로 나눔     
- 훈련세트와 테스트세트를 표준화 전처리 해줌 - 훈련세트의 통계값으로 테스트세트를 변환해야함     

k-최근접 이웃 분류기로 확률을 예측해보자     
- 타깃 데이터에 2개 이상의 클래스가 포함되어 있는 문제를 **다중 분류**라고 함     
![image](https://github.com/user-attachments/assets/f342cdab-a261-4dbf-82f7-7543dbdd6326)     
- 훈련세트와 테스트 점수는 현재 필요 X     
![image](https://github.com/user-attachments/assets/fb69694e-4b38-45ca-a0ca-03f13b79051f)     
- classes_속성에 KNeighborsClassifier에서 정렬된 타깃값 저장되어있음 - 이름순     
- predict()메서드로 타깃 값에 대한 예측 출력     
- predict_proba()메서드로 클래스별 확률 값 반환     
- 네 번째 샘플의 최근접 이웃 클래스의 indexes를 확인함으로서 계산한 확률이 가장 가까운 이웃의 비율이 맞는지 확인 가능     
한계: 3개의 최근접 이웃을 사용하기 때문에 가능한 확률은 : 0/3, 1/3, 2/3, 3/3이 전부임. 항상 정해진 확률만 출력함     

### 로지스틱 회귀     
- 로지스틱 회귀는 이름은 회귀이지만 **분류**모델이다.     
- 선형회귀와 동일하게 선형방정식을 학습함 ![image](https://github.com/user-attachments/assets/617f93d7-0f24-436e-8033-391fcd542640)     
- z는 어떤 값도 가능하지만, 확률이 되려면 0~1 사이의 값이 되어야하므로 시그모이드 함수를 사용함     
-  ![image](https://github.com/user-attachments/assets/75f74c74-a6d0-496d-846f-6d7fc26ff47c)     
-  ![image](https://github.com/user-attachments/assets/62b8f5aa-0e66-4504-ac09-b664d00859e4)
          
  +) 훈련 전 간단한 **이진 분류**(도미, 빙어)를 해보자 - 시그모이드 함수 출력이 0.5보다 크면 양성 클래스, 작으면 음성 클래스로 판단     
    - 넘파이 배열은 True, False 값을 전달해서 행을 선택함 : **불리언 인덱싱**     
    - ![image](https://github.com/user-attachments/assets/206c589a-143d-46d4-ae3f-aeecee588081)     
    - 불리언 인덱싱은 True에 해당하는 위치의 값을 선택, False 값은 무시-> True에 해당하는 인덱스 0과 2의 값인 'A'와 'C'가 선택됨     
    - 위와 같은 방식으로 훈련세트에서 도미(Brem)와 빙어(Smelt)의 행만 골라내보자     
    - ![image](https://github.com/user-attachments/assets/ecb55756-3497-425f-b6d1-d1bb268a7f7b)     
    - 비교 연산자를 사용하면 도미와 빙어의 행을 모두 True로 만들고 골라낼 수 있음 - ex) train_target == 'Bream'     
    - OR 연산자 (|)를 통해서 도미와 빙어에 대한 행을 골라낼 수 있음     
    - 이 데이터로 로지스틱 회귀 모델을 훈련하면     
    - ![image](https://github.com/user-attachments/assets/30068c95-1cce-46fb-bd7f-8c4810bbfdb5)     
 
    - ![image](https://github.com/user-attachments/assets/d6d4e5c2-f7f3-496d-9979-33143444454c)     
    - 훈련한 모델을 사용해 train_bream_smelt의 첫 5개 샘플을 예측함     
    - **predict_proba()** 메서드로 예측한 음성클래스와 양성클래스에 대한 확률 출력     
    - classes_ 속성을 이용해 어떤 것이 음성(0)이고, 양성(1)인지 확인 - 빙어(S)가 양성     
    - lr.coef_, lr.intercept_로 로지스틱 회귀가 학습한 선형 방정식의 계수 확인     
    - 따라서 로지스틱 회귀가 학습한 방정식은 ![image](https://github.com/user-attachments/assets/3a1269b2-9d74-419c-95c1-f6621ccd36d6)인 것을 알 수 있다.     
    - **decision_function()** 메서드로 양성 클래스에 대한 z값 출력     
    - np.exp()함수를 사용해 z값을 시그모이드 함수에 통과시켜 확률을 얻을 수 있음 => decision_function() 메서드 출력의 두번째 열의 값과 동일함  = decision_function() 메서드는 양성클래스에 대한 z값을 반환한다는 것을 알 수 있다.      


이제 로지스틱 회귀로 다중분류를 수행해보자     
![image](https://github.com/user-attachments/assets/2ca1b690-a1b3-40fa-bfb6-61677c7def98)     
- LogisticRegression 클래스는 기본적으로 반복적인 알고리즘을 사용함 - max_iter 매개변수에서 반복횟수를 지정함     
- LogisticRegression은 기본적으로 계수의 제곱을 규제함(like 릿지) : L2 규제 - 규제 제어 매개변수: C(작을수록 규제가 커짐)     
- 여기서는 7개의 생선데이터가 모두 들어있는 train_scaled, train_target을 사용함     
![image](https://github.com/user-attachments/assets/123e991a-87ed-463d-ba25-8f0f5e312909)     
- 테스트세트 첫 5개 샘플에 대한 예측과 예측확률 출력     
![image](https://github.com/user-attachments/assets/981b9644-d768-4ba8-b89b-363fe766f94a)     
- 다중 분류의 선형방정식의 coef_, intercept_의 크기를 출력     
- 이 데이터는 5개의 특성을 사용하므로 coef_의 배열의 열은 5개임     
- coef_의 배열의 행과 intercept_이 7임: z를 7개 계산한다는 의미 - 다중분류는 클래스마다 z값을 하나씩 계산하고 가장 높은 z값을 출력하는 클래스가 예측 클래스가 됨     
- 다중분류는 소프트맥스 함수를 사용해 7개의 z값을 확률로 변환 (이진분류는 시그모이드함수 이용)     
- 소프트맥스 함수는 다중분류에서 여러 선형방정식의 출력 결과를 정규화하여 합이 1이 되도록 만듬     
- 소프트맥스 ![image](https://github.com/user-attachments/assets/917393b0-2b75-4564-8056-07896d1c687d)     
![image](https://github.com/user-attachments/assets/b3c13370-090e-4b49-85ae-d1ab68b0b78c)          
- decision_function()메서드로 z1_z7까지의 값을 구한 다음 소프트맥스 함수를 사용해 확률로 변환     
- softmax()의 axis 매개변수는 소프트맥스를 계산할 축을 지정함. - axis=1으로 지정해 각 행, 즉 각 샘플에 대해 소프트맥스 계산 / axis 매개변수를 지정하지 않으면 배열 전체에 대한 소프트맥스를 계산함     
- 앞서 구한 proba 배열과 결과가 일치하므로 성공 !     









