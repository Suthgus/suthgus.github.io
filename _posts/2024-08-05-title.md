---
layout: post
title:  "회귀 알고리즘과 모델 규제"
date : 2024-08-05 00:25:20 +0700
---
# 3-1 k-최근접 이웃 회귀

### k-최근접 이웃 회귀

지도 학습 알고리즘은 분류와 회귀로 나뉜다. 회귀는 임의의 어떤 숫자를 예측하는 것을 말한다.     
농어의 길이, 높이, 두께 데이터를 이용해서 무게를 예측할 수 있을까?    

k-최근접 이웃 알고리즘은 회귀에도 작동한다. 여기서 타깃은 어떤 클래스가 아니라, 임의의 수치이다.      
수치 예측 방법: 예측하려는 샘플에 가장 가까운 샘플 k개를 선택한다. 이웃의 샘플들의 수치의 평균을 구한다.      

농어의 길이로 무게를 예측한다면, 길이가 특성이고 무게가 타깃이 된다.      
![image](https://github.com/user-attachments/assets/209e1f06-eaf0-4d7f-bf46-7b2c195510e2)     
머신러닝 모델에 사용하기 전에 훈련세트와 테스트세트로 나눈다.     
그리고 사이킷런에 사용할 훈련세트는 2차원 배열이어야하기 때문에 넘파이의 reshape() 메서드를 통해 2차원 배열로 만들어주어야한다.      
![image](https://github.com/user-attachments/assets/0bb8bf57-54a6-4430-b2e1-19893751cf3f)     
![image](https://github.com/user-attachments/assets/a090a8b6-90b6-4688-8b8f-564b9b68a71f)     
- 넘파이는 배열의 크기를 자동으로 지정하는 기능을 제공하는데, 크기에 -1을 지정하면 나머지 원소 개수로 모두 채울 수 있다. 따라서 배열의 전체 원소 개수를 몰라도 사용할 수 있어 편리하다.      

### 결정계수 (R^2)     
![image](https://github.com/user-attachments/assets/70e794cd-2411-4918-885a-0fff34ceef72)     
![image](https://github.com/user-attachments/assets/d8675c5c-d054-4b0c-8fba-66054805f4cf)     
k-최근접 이웃 회귀 알고리즘 클래스는 KNeighborsRegressor이다.      
객체를 생성하고 fit() 메서드로 회귀 모델을 훈련했다.      
그렇게 나온 score은 회귀를 평가하는 **결정계수(R^2)**이다.      
(훈련세트를 사용해서 모델을 훈련하고 테스트세트로 모델을 평가했다.)     
![image](https://github.com/user-attachments/assets/326e54e1-94dd-4260-ba23-8e2719919a78)     
타깃이 예측에 가까워지면 (분모가 0에 가까워지기 때문에) 1에 가까운 값이 된다.      

앞에서 훈련한 모델을 사용해서 훈련세트의 R^2점수를 확인해보자.     
![image](https://github.com/user-attachments/assets/492e1741-32df-48f5-8406-f37f65c35e63)     
이상한 점을 찾았는가?      
모델을 훈련세트에 훈련하면 훈련세트에 잘 맞는 모델이 만들어지기 때문에 훈련세트의 점수가 좀 더 높게 나온다.      
- 과대적합: 훈련세트에서 높은 점수, 테스트세트에서 매우 낮은 점수 ; 새로운 샘플을 예측할 때 잘 동작하지 않을 것     
- 과소적합: 훈련세트 점수 < 테스트세트 점수 or 두 점수 모두 낮은 점수 ; 모델이 너무 단순해서 훈련세트에 적절히 훈련되지 않은 경우     
따라서 우리는 이 모델이 과소적합인 것을 발견했다. 모델을 복잡하게, 즉 훈련세트에 더 잘 맞게 만들어서 이 문제를 해결해보자.      
- 이웃의 개수(k)를 줄이기- 훈련세트의 국지적인 패턴에 민감해질 것임 // 반대로, 과대적합일 경우 k값을 늘리면 됨     
![image](https://github.com/user-attachments/assets/803c6076-6f5a-4635-a6ce-bde087dd36cb)     


# 3-2 선형회귀     
knn 모델은 한계가 있다.      
knn모델은 가장 가까운 이웃 샘플의 평균을 구해 수치를 예측한다.      
따라서 새로운 샘플이 훈련 세트의 범위를 벗어나면 엉뚱한 값을 예측한다. 즉, 농어가 아무리 커도 무게가 더 늘어나지 않는다.     
따라서 다른 알고리즘을 사용해야한다.       

선형회귀: 특성과 타깃 사이의 관계를 가장 잘 나타내는 직선을 학습하는 알고리즘     
- y=ax+b 의 직선의 방정식에서 이 데이터에 가장 잘 맞는 a와 b를 찾는 것     
![image](https://github.com/user-attachments/assets/ea3177f7-1a60-4ae6-a128-c0a136f5bd7c)     
사이킷런의 모델 클래스들은 훈련(fit), 평가(score), 예측(predict)하는 메서드 이름이 모두 동일하다.     
- LinearRegression클래스가 찾은 a,b는 lr객체의 coef_와 intercept_속성에 저장되어있다.      
![image](https://github.com/user-attachments/assets/9caf8761-ec59-4fd9-a625-32cba910115c)     
- 모델 파라미터: coef_와 intercept와 같이 머신러닝 알고리즘이 찾은 (최적의) 값     
![image](https://github.com/user-attachments/assets/c3c3a4e6-5b87-4a40-a0c6-da025d81ecea)     
![image](https://github.com/user-attachments/assets/c77063ba-43e6-4148-a391-dd1d03ae9ed6)     
이렇게 훈련세트 범위를 벗어난 농어의 무게를 예측할 수 있고, 이 예측은 직선의 연장선에 있다.      
![image](https://github.com/user-attachments/assets/241b650d-c452-485b-9216-145cb5866707)     
결과가 전체적으로 높지 않은 것을 확인할 수 있고, 그래프 왼쪽 아래를 보면 무게가 음수가 될 수도 있다, 이는 현실에서 있을 수 없는 일이다.     

 ### 다항회귀      
최적의 곡선을 찾아보자. 이런 2차 방정식의 그래프를 그리려면 길이를 제곱한 항이 훈련세트에 추가되어야한다.      
이는 넘파이 column_stack()함수를 사용하여 농어 길이의 제곱 값을 원래 데이터 앞에 붙이면 된다.      
![image](https://github.com/user-attachments/assets/a5af639f-fe67-46a5-80b5-43d78084a18a)     
이렇게 제곱한 값을 원래의 배열 앞에 나란히 붙였다.      
이제 train_poly를 사용해 선형회귀모델을 다시 훈련해서 2차 방정식의 a,b,c를 찾아보자.      
![image](https://github.com/user-attachments/assets/508d08d9-5fb1-4765-8978-76ba97f6192a)     
![image](https://github.com/user-attachments/assets/7685e007-3f08-4bd3-a1c3-8fe55cf1a661)     
모델이 학습한 그래프는 ![image](https://github.com/user-attachments/assets/fabda719-e7c9-424d-90f1-296668ff7cf4) 이다.      
![image](https://github.com/user-attachments/assets/021ffcf4-0413-4b10-b6a8-f7371c3445ac)     
점수는 크게 높아졌지만, 여전히 테스트 세트의 점수가 여전히 높은 것으로 보아 과소적합이 아직 남아있는 것을 확인할 수 있다.      
조금 더 복잡한 모델이 필요하다.      

### 특성공학과 규제     
38
