---
layout: post
title:  "데이터 다루기"
date : 2024-07-29 00:25:20 +0700
---

# 02 데이터 다루기
## 2-1 훈련 세트와 테스트 세트

이전 포스팅에서는 k-최근접 이웃 알고리즘을 사용해서 도미와 빙어를 분류하였다.    
이미 답을 알고있는 상태에서 훈련 후, 같은 데이터를 분류하는 것이기 때문에 정확도가 100%인 결과는 당연한 것이다. 

### 지도학습과 비지도학습    
머신러닝 알고리즘은 지도학습과 비지도 학습으로 나눌 수 있다. 
- *지도학습*: 훈련하기 위한 입력(데이터)와 타깃(정답)이 필요하다. ex) k-최근접 이웃 알고리즘
- 입력과 타깃을 훈련 데이터라고 한다.
- 정답이 있으니 알고리즘이 정답을 맞히는 것을 학습한다.
![image](https://github.com/user-attachments/assets/e819ae01-4439-4f4f-a208-0b83cf490d99)    

- *비지도 학습*: 타깃 없이 입력 데이터만 사용한다. -> 무언가를 맞힐 수 없고, 데이터의 특징을 파악하거나 변형하는데 도움을 준다.

### 훈련세트와 테스트세트    
머신러닝 알고리즘의 성능을 제대로 평가하기 위해서는 훈련 데이터와 평가에 사용하는 데이터가 달라야한다.    
따라서 이미 준비된 데이터를 테스트세트(평가에 사용하는 데이터)와 훈련세트(훈련에 사용하는 데이터)로 나누어 활용한다.     

따라서 이전 포스트에서 훈련에 사용한 데이터를 이용해 이 모델의 정확도를 평가하는 것은 적절하지 않다.    
이를 위해서 훈련 데이터에서 일부를 떼어 내어 테스트 데이터로 사용하도록 하자.    
![image](https://github.com/user-attachments/assets/268a3e66-2285-40d5-9f70-d3e1b418cc2d)    

두 파이썬 리스트를 순회하면서 각 생선의 무게를 하나의 리스트로 담은 2차원 리스트로 만들자.     
![image](https://github.com/user-attachments/assets/2e290b63-3cd3-4f01-aa3e-b515045f3f79)    
이때 하나의 생선 데이터를 샘플이라고 한다. 전체 49개의 샘플에서 35개를 훈련세트로, 나머지 14개를 테스트 데이터로 사용하자.     
![image](https://github.com/user-attachments/assets/c2090726-43b7-422b-a75c-d91da524453e)    

KNeighborsClassifier 클래스를 임포트하고 모델 객체를 만들자.      
![image](https://github.com/user-attachments/assets/512d51c5-d6aa-4edf-b0d4-e30b5265edbb)    
슬라이싱을 이용하여 전체 49개의 샘플에서 35개를 훈련세트로 선택해주고, 나머지 14개를 테스트세트로 선택해주자.    
![image](https://github.com/user-attachments/assets/da1eaf5f-ba28-4706-a5e2-983214758efd)     

훈련세트로 fit() 메서드를 호출해 모델을 훈련하고, 테스트 세트로 score() 메서드를 호출해 평가해보자.    
![image](https://github.com/user-attachments/assets/ef94b19a-1671-4e06-9869-1e760bfaca44)
정확도가 0.0인 것을 확인할 수 있다.    
무엇을 잘못한 것일까???

### 샘플링 편향      
훈련세트와 테스트세트를 나눌 때 마지막 14개를 테스트세트로 했다.    
따라서 훈련세트에 빙어가 하나도 들어가지 않았기 때문에 올바른 분류를 하지 못한 것이다. 
이렇게 훈련세트와 테스트세트에 샘플이 골고루 섞이지 않고, 샘플링이 한쪽으로 치우쳤다면 *샘플링 편향*이라고 한다. 
훈련세트와 테스트세트 나누려면 도미와 빙어가 골고루 섞이도록 해야한다.      
이 작업을 간편하게 처리하기 위해서 넘파이 라이브러리를 이용한다.    

### 넘파이    
- 파이썬의 대표적인 배열(array) 라이브러리이다.    
- 고차원의 배열을 손쉽게 만들고 조작할 수 있는 간편한 도구를 많이 제공한다.     
![image](https://github.com/user-attachments/assets/5d554d68-9e4b-45d6-b844-b1a73bb75db0)     
- 시작점이 왼쪽 위이다. (보통의 xy좌표계는 왼쪽 아래에서 시작)

생선 데이터(파이썬 리스트)를 2차원 넘파이 배열로 변환해보자. : array()함수에 파이썬 리스트를 전달하면 됨   
![image](https://github.com/user-attachments/assets/c0ad9ece-7904-47ed-9134-99c4760ff098)     
![image](https://github.com/user-attachments/assets/17155e1a-9a1d-490c-80dd-7403022351e1)      
![image](https://github.com/user-attachments/assets/96760e1a-b53c-40bd-bc4f-48b63536e79f)     
넘파이는 배열의 차원을 구분하기 쉽도록 행과 열을 가지런히 출력한다.     
![image](https://github.com/user-attachments/assets/17a50a1f-a82a-4215-a05e-4587b3dc9659)     

생선의 데이터를 넘파이 배열로 준비했으므로, 이 배열에서 랜덤하게 샘플을 선택해 훈련세트와 테스트세트로 만들어보자.    
여기서 주의할 점은 input_arr과 target_arr에서 같은 위치는 함께 선택되어야 한다는 점이다.     
![image](https://github.com/user-attachments/assets/e6549ff5-6e1d-40d6-9393-7bad27490f01)     

넘파이 arrange()함수를 사용하여 0부터 48까지(총 49개) 1씩 증가하는 인덱스를 만든 후 인덱스를 섞어보자.    
![image](https://github.com/user-attachments/assets/447d84ff-5593-4fa1-a3f9-3461bf0ed1b2)    
![image](https://github.com/user-attachments/assets/267d1315-0184-4031-9468-3d551a8fcd01)    
0부터 48까지 정수가 잘 섞인 것을 확인할 수 있다. 이제 이 섞인 인덱스를 사용해 전체 데이터를 훈련세트와 테스트세트로 나누어 보자.    
- 배열 인덱싱: 여러 개의 인덱스로 한 번에 여러 개의 원소를 선택할 수 있음    
- ex) input_arr에서 2번째와 네번째 샘플을 선택해서 출력해보자    
-  ![image](https://github.com/user-attachments/assets/3748452d-14d7-4d1b-ae3b-77d0b430e4b5)

앞서 만든 index 배열의 처음 35개를 훈련세트로 만들어보자.    
![image](https://github.com/user-attachments/assets/cbe15a8b-0854-45de-999f-30feb03e5d00)    
이제 나머지 14개를 테스트세트로 만들어보자.     
![image](https://github.com/user-attachments/assets/f4d6992b-b320-41ac-8ac5-95b5ace22190)    
모든 데이터가 준비되었다.     

훈련세트와 테스트세트에 도미와 빙어가 잘 섞여있는지 산점도를 그려보자     
![image](https://github.com/user-attachments/assets/e102762f-167b-48c3-b2f1-831a1d65f119)    
파란색이 훈련세트이고, 주황색이 테스트세트이다. 양쪽에 도미와 빙어가 모두 섞여 있는 것을 확인할 수 있다.     
이제 앞서 만든 훈련세트와 테스트세트로 모델 훈련을 시켜보자.    
fit()메서드를 실행할 때마다 KNeighborsClassifier 클래스의 객체는 학습한 모든 것을 잃어버린다.    
이전 모델을 그대로 두고 싶다면 KNeighborsClassifier 클래스 객체를 새로 만들어야하지만, 여기에서는 이전에 만든 kn 객체를 그대로 사용하도록 하자.    
![image](https://github.com/user-attachments/assets/7f532afd-e435-4dcb-a3c8-277c4efed956)    
![image](https://github.com/user-attachments/assets/d73ea03d-79d4-405d-be9d-5947a9575ee2)    
인덱스를 섞어서 만든 train 데이터로 모델을 훈련시킨 후, test 데이터로 테스트 한 결과, 100%의 정확도를 달성하였다.    
![image](https://github.com/user-attachments/assets/d848f8d3-bbdb-4249-9ad3-dced3c5d8b8f)     
predict() 메서드로 테스트 세트의 예측 결과와 실제 타깃을 확인한 결과도 일치하는 것을 확인하였다.   
- 두 결과값은 array()로 감싸있는 것을 볼 수 있다. 이 값은 넘파이 배열을 의미한다.
- 사실, 사이킷런 모델의 입력과 출력은 모두 넘파이 배열이다.    

## 2-2 데이터 전처리    
### 넘파이로 데이터 준비하기    
![image](https://github.com/user-attachments/assets/593e0811-1480-430d-ab68-dc2d364196b2)    
![image](https://github.com/user-attachments/assets/1cf90de1-c660-4b5e-b3b5-ab84f7a092cb)    
- ![image](https://github.com/user-attachments/assets/ee85c268-5dbf-439f-a3e2-bb016865c1a7)    
- 넘파이의 column_stack()함수는 전달받은 리스트를 일렬로 세운 다음 차례대로 나란히 연결한다.     
- 위의 예시처럼 간단한 2개의 리스트를 나란히 붙이면, 파이썬 튜플로 전달한다. 결과로 (3,2)크기의 배열, 즉 3행2열의 배열이 만들어진다.    
- 튜플: 리스트와 비슷, 원소에 순서가 있지만 한 번 만들어진 튜플은 수정 불가, 매개변수의 값으로 많이 사용됨.

이제 위의 방법과 동일하게 fish_length와 fish_weight를 합쳐보자.    
![image](https://github.com/user-attachments/assets/dfd555db-af21-44c4-a27b-5e7016b70661)    
동일한 방법으로 타깃 데이터를 만들자.    
이전에는 원소가 하나인 리스트 [1], [0]을 여러 번 곱해서 타깃 데이터를 만들었지만, 넘파이에서는 np.ones()와 mp.zeros함수를 사용하여 각각 원하는 개수의 1과 0을 채운 배열을 만들 수 있다.     
- 예를 들면 ![image](https://github.com/user-attachments/assets/c588d9ee-3572-4fcd-93d0-4e477dcb524d)    
np.ones()와 mp.zeros 함수를 이용해 1이 35개인 배열과 0이 14개인 배열을 만들 수 있다.
그 다음 두 배열을 그대로 연결하면 된다. 이 때는 np.column_stack()함수를 사용하지 않고, 첫 번째 차원을 따라 배열을 연결하는 np.concatenate() 함수를 사용한다.
- ![image](https://github.com/user-attachments/assets/851d7f8e-67da-4f79-90e4-b5dc0a90b0d7)    
np.concatenate()함수를 사용해 타깃데이터를 만들어보자.
np.column_stack()과 마찬가지로 연결한 리스트나 배열을 튜플로 전달해야한다.    
![image](https://github.com/user-attachments/assets/f29f8c08-a36b-413f-86cb-acc730e729d1)    
![image](https://github.com/user-attachments/assets/004f47b0-6660-47a9-9951-7c4398205bf2)    
- 이렇게 넘파이 함수를 이용해 데이터를 준비해보았다. 데이터가 클수록 파이썬 리스트는 비효율적이기 때문에 넘파이 배열을 사용하는 것이 좋다.   

### 사이킷런으로 훈련세트와 테스트세트 나누기    
앞에서는 넘파이 배열의 인덱스를 직접 섞어서 훈련세트와 테스트세트로 나누었지만, 이는 번거롭다.    
사이킷런의 train_test_split() 함수를 사용해보도록 하자.    
이 함수는 리스트나 배열을 비율에 맞게 훈련세트와 테스트세트로 나누어 준다.     
![image](https://github.com/user-attachments/assets/77a97a73-c295-4727-a33b-6f7d339c13f5)    
나누고 싶은 리스트나 배열을 원하는 만큼 전달해서 이 함수를 사용해보자.    
![image](https://github.com/user-attachments/assets/f4a9d75a-b793-4687-a613-fe547baa8bb4)    
fish_data와 fish_target 2개의 배열을 전달했으므로 2개씩 나뉘어 총 4개의 배열이 반환된다.     
![image](https://github.com/user-attachments/assets/8c60b88a-a9cf-4297-b831-705b5259c47a)    
이 함수는 기본적으로 25%를 테스트세트로 떼어낸다.   
잘 나누었는지 확인하기 위해서는 shape속성으로 데이터의 크기를 출력해볼 수 있다.    
![image](https://github.com/user-attachments/assets/cbcf803d-7403-4be5-a2de-95ba497bd61b)    
![image](https://github.com/user-attachments/assets/22f82c7d-be25-4737-8e61-fca8a81f0b7c)    
훈련데이터와 테스트데이터를 각각 36개, 13개로 나누었다. 그리고 입력데이터는 2개의 열이 있는 2차원 배열이고 타깃 데이터는 1차원 배열이다.   
- 샘플링 편향을 막고 클래스 비율을 일정하게 하기 위해서는 stratify 매개변수에 타깃데이터를 전달하면 클래스 비율에 맞게 데이터를 나눈다.    
- 이는 훈련데이터가 작거나 특정 클래스의 샘플 개수가 적을 때 유용하다.
- ![image](https://github.com/user-attachments/assets/ed3d88c5-f4ab-4977-b3b2-e4888eb02d2b)    

### 수상한 도미 한 마리    
준비한 데이터로 k-최근접 이웃을 훈련해보자.   
![image](https://github.com/user-attachments/assets/ac7b434e-099a-48d1-ab47-1822c7eb00e6)   
테스트 세트의 도미와 빙어를 모두 올바르게 분류했다.    
![image](https://github.com/user-attachments/assets/607bb18b-fd8b-4644-835c-393af68f81db)    
하지만 도미(1) 데이터를 넣고 결과를 확인했지만 빙어(0)로 분류한 것을 알 수 있다.     

이 샘플을 다른 데이터와 함께 산점도로 그려 확실히 확인해보자.    
![image](https://github.com/user-attachments/assets/2738b5e4-9642-47ea-a57d-c9e7c12af724)    
![image](https://github.com/user-attachments/assets/a0984710-2c5f-4c35-94c6-b11816bd27ba)     
삼각형으로 표시된 샘플은 직관적으로 보았을 때 도미 데이터에 더 가까운 것을 알 수 있다.    
그렇다면 왜 이 모델은 왼쪽 밑의 빙어데이터에 더 가깝다고 판단한 것일까?    

indexes 배열을 사용해 훈련 데이터 중 이웃 샘플을 따로 구분해 그려보자.    
![image](https://github.com/user-attachments/assets/0f38d4ae-9192-4130-aaa7-9faf047507e0)    
![image](https://github.com/user-attachments/assets/1f64b561-e5b3-469d-9127-431b3cf6c7e1)    
![image](https://github.com/user-attachments/assets/11971f77-d3c8-493b-868c-6ff05e896e90)    
삼각형 샘플에 가장 가까운 5개의 샘플(다이아몬드)에 도미가 하나밖에 포함되지 않은 것을 확인할 수 있다. 이 데이터를 직접 확인해보면    
![image](https://github.com/user-attachments/assets/cd030e56-ffcb-4271-b578-3720a3c178e2)    
![image](https://github.com/user-attachments/assets/db9de104-4821-42dc-8723-7f2ef1f7bf24)    
산점도 상에서는 도미와 더 가까워보이는 데이터를 빙어로 분류한 문제를 해결하기 위해 이웃 샘플까지의 거리를 측정해보자.    
![image](https://github.com/user-attachments/assets/8c6676a5-880c-45d4-8655-8023ce1aabc6)    

### 기준을 맞춰라 
92보다 몇배는 되어보이지만 130인 것이 수상하다.     
그래프를 다시 살펴보니 x축의 범위보다 y축의 범위가 훨씬 넓은 것, 즉 스케일이 다른 것을 확인할 수 있다.    
x축의 범위를 y축과 동일하게 0~1000으로 맞추어보자.(xlim()이용)    
![image](https://github.com/user-attachments/assets/44b74d23-32ce-4c60-8d59-552bd4adc54c)
이렇듯 알고리즘은 샘플 간의 거리에 영향을 많이 받으므로, 제대로 사용하기 위해서는 특성값을 일정한 기준으로 맞춰 주어야 한다. = 전처리     
- 표준점수: 각 특성값이 0에서 표준편차의 몇 배만큼 떨어져 있는지를 나타냄-> 동일한 조건 하에서 비교 가능 = 원본 데이터에서 평균을 빼고 표준편차로 나누어주면 된다. 
- 훈련샘플을 전처리해주면, 샘플 또한 전처리 해주어야 한다. (훈련세트의 평균과 표준편차 이용)    
- 전처리를 해주면 스케일 차이 문제를 해소할 수 있기 때문에 도미데이터를 도미로 구분할 수 있다. 
